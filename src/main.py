# -*- coding: utf-8 -*-
"""
å²©çŸ³å›¾åƒåˆ†ç±» - ä¸»è®­ç»ƒè„šæœ¬
æ•´åˆäº†æ‰€æœ‰æœ€ä½³åŠŸèƒ½çš„å®Œæ•´è®­ç»ƒè§£å†³æ–¹æ¡ˆ

åŠŸèƒ½ç‰¹æ€§:
- æ”¯æŒå•æ¨¡å‹å’Œé›†æˆå­¦ä¹ 
- å¤šç§é¢„è®­ç»ƒæ¨¡å‹é€‰æ‹©
- æ™ºèƒ½æ•°æ®å¢å¼ºå’Œé¢„å¤„ç†
- é«˜æ•ˆè®­ç»ƒç­–ç•¥å’Œä¼˜åŒ–å™¨
- å®Œæ•´çš„è¯„ä¼°å’Œå¯è§†åŒ–
- GPU/CPUè‡ªé€‚åº”è®­ç»ƒ
- å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ

ä½¿ç”¨ç¤ºä¾‹:
    # å¿«é€Ÿæµ‹è¯•
    python main.py --mode quick

    # å¿«é€Ÿè®­ç»ƒ
    python main.py --mode fast

    # å®Œæ•´è®­ç»ƒ
    python main.py --model resnet50 --epochs 50

    # é›†æˆå­¦ä¹ 
    python main.py --ensemble --epochs 30
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import argparse
import time
import os
import sys
import warnings
import numpy as np
import matplotlib.pyplot as plt

warnings.filterwarnings('ignore')

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import Config
from models import get_model
from trainer import Trainer
from utils import evaluate_model, plot_confusion_matrix, plot_class_performance, print_model_info

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='å²©çŸ³å›¾åƒåˆ†ç±»è®­ç»ƒè„šæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
    # å¿«é€Ÿæµ‹è¯• (5è½®è®­ç»ƒ)
    python main.py --mode quick

    # å¿«é€Ÿè®­ç»ƒ (15è½®è®­ç»ƒ)
    python main.py --mode fast

    # å®Œæ•´è®­ç»ƒ (30è½®è®­ç»ƒ)
    python main.py --model resnet50 --epochs 30

    # é›†æˆå­¦ä¹ 
    python main.py --ensemble --epochs 25

    # GPUè®­ç»ƒ (å¦‚æœå¯ç”¨)
    python main.py --model resnet50 --epochs 50 --batch_size 64
        """
    )

    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model', type=str, default='resnet50',
                       choices=['resnet18', 'resnet34', 'resnet50', 'resnet101',
                               'efficientnet_b0', 'efficientnet_b1', 'custom_cnn'],
                       help='é€‰æ‹©æ¨¡å‹æ¶æ„ (é»˜è®¤: resnet50)')

    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=30,
                       help='è®­ç»ƒè½®æ•° (é»˜è®¤: 30)')
    parser.add_argument('--batch_size', type=int, default=32,
                       help='æ‰¹æ¬¡å¤§å° (é»˜è®¤: 32)')
    parser.add_argument('--lr', type=float, default=0.001,
                       help='å­¦ä¹ ç‡ (é»˜è®¤: 0.001)')

    # è®­ç»ƒç­–ç•¥
    parser.add_argument('--optimizer', type=str, default='adamw',
                       choices=['adam', 'adamw', 'sgd'],
                       help='ä¼˜åŒ–å™¨é€‰æ‹© (é»˜è®¤: adamw)')
    parser.add_argument('--scheduler', type=str, default='cosine',
                       choices=['step', 'cosine', 'plateau'],
                       help='å­¦ä¹ ç‡è°ƒåº¦å™¨ (é»˜è®¤: cosine)')

    # æ¨¡å‹è®¾ç½®
    parser.add_argument('--pretrained', action='store_true', default=True,
                       help='æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ (é»˜è®¤: True)')
    parser.add_argument('--dropout', type=float, default=0.5,
                       help='Dropoutç‡ (é»˜è®¤: 0.5)')

    # é›†æˆå­¦ä¹ 
    parser.add_argument('--ensemble', action='store_true',
                       help='æ˜¯å¦ä½¿ç”¨é›†æˆå­¦ä¹ ')
    parser.add_argument('--ensemble_models', nargs='+',
                       default=['resnet18', 'resnet34', 'resnet50'],
                       help='é›†æˆå­¦ä¹ ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨')

    # è®­ç»ƒæ¨¡å¼
    parser.add_argument('--mode', type=str, default='full',
                       choices=['quick', 'fast', 'full'],
                       help='è®­ç»ƒæ¨¡å¼: quick(5è½®æµ‹è¯•), fast(15è½®å¿«é€Ÿ), full(å®Œæ•´è®­ç»ƒ)')

    # ç³»ç»Ÿè®¾ç½®
    parser.add_argument('--mixed_precision', action='store_true', default=True,
                       help='æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (é»˜è®¤: True)')
    parser.add_argument('--num_workers', type=int, default=4,
                       help='æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•° (é»˜è®¤: 4)')

    # è¾“å‡ºè®¾ç½®
    parser.add_argument('--save_plots', action='store_true', default=True,
                       help='æ˜¯å¦ä¿å­˜å›¾è¡¨ (é»˜è®¤: True)')
    parser.add_argument('--no_plots', action='store_true',
                       help='ä¸ä¿å­˜å›¾è¡¨ (è¦†ç›– --save_plots)')

    return parser.parse_args()

def update_config(args):
    """æ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®"""
    # åŸºæœ¬å‚æ•°
    Config.MODEL_TYPE = args.model
    Config.EPOCHS = args.epochs
    Config.BATCH_SIZE = args.batch_size
    Config.LEARNING_RATE = args.lr

    # è®­ç»ƒç­–ç•¥
    Config.OPTIMIZER = args.optimizer
    Config.LR_SCHEDULER = args.scheduler

    # æ¨¡å‹è®¾ç½®
    Config.PRETRAINED = args.pretrained
    Config.DROPOUT_RATE = args.dropout

    # é›†æˆå­¦ä¹ 
    Config.ENSEMBLE = args.ensemble
    Config.ENSEMBLE_MODELS = args.ensemble_models

    # ç³»ç»Ÿè®¾ç½®
    Config.MIXED_PRECISION = args.mixed_precision and torch.cuda.is_available()
    Config.NUM_WORKERS = args.num_workers
    Config.SAVE_PLOTS = args.save_plots and not args.no_plots

    # æ ¹æ®è®­ç»ƒæ¨¡å¼è°ƒæ•´å‚æ•°
    if args.mode == 'quick':
        Config.EPOCHS = 5
        Config.BATCH_SIZE = 16
        Config.EARLY_STOPPING = False
        Config.MODEL_TYPE = 'resnet18'
        print("ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼: 5è½®è®­ç»ƒ, ResNet18, å°æ‰¹æ¬¡")
    elif args.mode == 'fast':
        Config.EPOCHS = 15
        Config.BATCH_SIZE = 64
        Config.MODEL_TYPE = 'resnet18'
        print("âš¡ å¿«é€Ÿè®­ç»ƒæ¨¡å¼: 15è½®è®­ç»ƒ, ResNet18, å¤§æ‰¹æ¬¡")
    else:
        print("ğŸ”¬ å®Œæ•´è®­ç»ƒæ¨¡å¼: è‡ªå®šä¹‰å‚æ•°")

def create_efficient_model(model_type='resnet18', num_classes=9, pretrained=True, dropout_rate=0.5):
    """åˆ›å»ºé«˜æ•ˆçš„æ¨¡å‹ï¼ˆé’ˆå¯¹å¿«é€Ÿè®­ç»ƒä¼˜åŒ–ï¼‰"""
    if model_type == 'resnet18':
        model = models.resnet18(pretrained=pretrained)
        # æ™ºèƒ½å†»ç»“ç­–ç•¥ï¼šåªè®­ç»ƒæœ€åä¸€å±‚å’Œlayer4
        for param in model.parameters():
            param.requires_grad = False
        for param in model.layer4.parameters():
            param.requires_grad = True

        num_features = model.fc.in_features
        model.fc = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(num_features, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate * 0.6),
            nn.Linear(256, num_classes)
        )
    elif model_type == 'resnet34':
        model = models.resnet34(pretrained=pretrained)
        # è§£å†»æ›´å¤šå±‚ä»¥è·å¾—æ›´å¥½æ€§èƒ½
        for param in model.parameters():
            param.requires_grad = False
        for param in model.layer4.parameters():
            param.requires_grad = True
        for param in model.layer3.parameters():
            param.requires_grad = True

        num_features = model.fc.in_features
        model.fc = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(num_features, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate * 0.6),
            nn.Linear(512, num_classes)
        )
    else:
        # ä½¿ç”¨é€šç”¨æ¨¡å‹åˆ›å»ºå‡½æ•°
        model = get_model(model_type, num_classes, pretrained, dropout_rate)

    return model

def get_optimized_data_loaders(batch_size=32, num_workers=4, mode='full'):
    """è·å–ä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨"""
    # æ ¹æ®æ¨¡å¼è°ƒæ•´æ•°æ®å¢å¼ºå¼ºåº¦
    if mode == 'quick':
        # å¿«é€Ÿæ¨¡å¼ï¼šæœ€ç®€å•çš„å¢å¼º
        train_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(0.5),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    elif mode == 'fast':
        # å¿«é€Ÿè®­ç»ƒï¼šä¸­ç­‰å¢å¼º
        train_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(0.5),
            transforms.RandomRotation(15),
            transforms.ColorJitter(brightness=0.1, contrast=0.1),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    else:
        # å®Œæ•´æ¨¡å¼ï¼šå¼ºæ•°æ®å¢å¼º
        train_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(0.5),
            transforms.RandomVerticalFlip(0.3),
            transforms.RandomRotation(30),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

    test_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # åŠ è½½æ•°æ®é›†
    train_dataset = datasets.ImageFolder('Rock Data/train', transform=train_transform)
    valid_dataset = datasets.ImageFolder('Rock Data/valid', transform=test_transform)
    test_dataset = datasets.ImageFolder('Rock Data/test', transform=test_transform)

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,
                             num_workers=num_workers, pin_memory=torch.cuda.is_available())
    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False,
                             num_workers=num_workers, pin_memory=torch.cuda.is_available())
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,
                            num_workers=num_workers, pin_memory=torch.cuda.is_available())

    return train_loader, valid_loader, test_loader, train_dataset.classes

def train_single_model(args):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
    print("=" * 70)
    print("ğŸš€ å²©çŸ³å›¾åƒåˆ†ç±» - å•æ¨¡å‹è®­ç»ƒ")
    print("=" * 70)

    # æ£€æŸ¥æ•°æ®
    if not os.path.exists('Rock Data'):
        print("âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿ Rock Data æ–‡ä»¶å¤¹åœ¨å½“å‰ç›®å½•")
        return None

    # è®¾å¤‡ä¿¡æ¯
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    if torch.cuda.is_available():
        print(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

    try:
        # åŠ è½½æ•°æ®
        print("\nğŸ“Š åŠ è½½æ•°æ®...")
        train_loader, valid_loader, test_loader, class_names = get_optimized_data_loaders(
            batch_size=Config.BATCH_SIZE,
            num_workers=Config.NUM_WORKERS,
            mode=args.mode
        )

        print(f"   è®­ç»ƒæ ·æœ¬: {len(train_loader.dataset):,}")
        print(f"   éªŒè¯æ ·æœ¬: {len(valid_loader.dataset):,}")
        print(f"   æµ‹è¯•æ ·æœ¬: {len(test_loader.dataset):,}")
        print(f"   ç±»åˆ«æ•°é‡: {len(class_names)}")

        # åˆ›å»ºæ¨¡å‹
        print(f"\nğŸ§  åˆ›å»ºæ¨¡å‹: {Config.MODEL_TYPE}")
        if args.mode in ['quick', 'fast']:
            model = create_efficient_model(
                model_type=Config.MODEL_TYPE,
                num_classes=len(class_names),
                pretrained=Config.PRETRAINED,
                dropout_rate=Config.DROPOUT_RATE
            )
        else:
            model = get_model(
                model_type=Config.MODEL_TYPE,
                num_classes=len(class_names),
                pretrained=Config.PRETRAINED,
                dropout_rate=Config.DROPOUT_RATE
            )

        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        print_model_info(model)

        # åˆ›å»ºè®­ç»ƒå™¨
        print(f"\nğŸƒ å¼€å§‹è®­ç»ƒ ({Config.EPOCHS} è½®)...")
        trainer = Trainer(
            model=model,
            train_loader=train_loader,
            valid_loader=valid_loader,
            test_loader=test_loader,
            config=Config
        )

        # è®­ç»ƒæ¨¡å‹
        start_time = time.time()
        history, test_acc, predictions, targets = trainer.train()
        total_time = time.time() - start_time

        print(f"\nâ±ï¸  æ€»è®­ç»ƒæ—¶é—´: {total_time/60:.1f} åˆ†é’Ÿ")

        # ç»˜åˆ¶è®­ç»ƒå†å²
        if Config.SAVE_PLOTS:
            trainer.plot_training_history()

        # è¯„ä¼°æ¨¡å‹
        print("\nğŸ“ˆ æ¨¡å‹è¯„ä¼°...")
        results = evaluate_model(
            predictions=predictions,
            targets=targets,
            class_names=class_names,
            save_dir=Config.RESULTS_DIR if Config.SAVE_PLOTS else None
        )

        # ç»˜åˆ¶ç»“æœ
        if Config.SAVE_PLOTS:
            plot_confusion_matrix(
                cm=results['confusion_matrix'],
                class_names=class_names,
                save_path=os.path.join(Config.RESULTS_DIR, 'confusion_matrix.png')
            )

            plot_class_performance(
                precision=results['precision'],
                recall=results['recall'],
                f1=results['f1_score'],
                class_names=class_names,
                save_path=os.path.join(Config.RESULTS_DIR, 'class_performance.png')
            )

        return test_acc, results, trainer

    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None

def train_ensemble_models(args):
    """è®­ç»ƒé›†æˆæ¨¡å‹"""
    print("=" * 70)
    print("ğŸ¤ å²©çŸ³å›¾åƒåˆ†ç±» - é›†æˆå­¦ä¹ è®­ç»ƒ")
    print("=" * 70)

    # æ£€æŸ¥æ•°æ®
    if not os.path.exists('Rock Data'):
        print("âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿ Rock Data æ–‡ä»¶å¤¹åœ¨å½“å‰ç›®å½•")
        return None

    # è®¾å¤‡ä¿¡æ¯
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")

    try:
        # åŠ è½½æ•°æ®
        print("\nğŸ“Š åŠ è½½æ•°æ®...")
        train_loader, valid_loader, test_loader, class_names = get_optimized_data_loaders(
            batch_size=Config.BATCH_SIZE,
            num_workers=Config.NUM_WORKERS,
            mode=args.mode
        )

        print(f"   è®­ç»ƒæ ·æœ¬: {len(train_loader.dataset):,}")
        print(f"   éªŒè¯æ ·æœ¬: {len(valid_loader.dataset):,}")
        print(f"   æµ‹è¯•æ ·æœ¬: {len(test_loader.dataset):,}")
        print(f"   é›†æˆæ¨¡å‹: {Config.ENSEMBLE_MODELS}")

        # è®­ç»ƒå¤šä¸ªæ¨¡å‹
        models = {}
        val_accuracies = []

        for i, model_type in enumerate(Config.ENSEMBLE_MODELS):
            print(f"\nğŸ§  è®­ç»ƒæ¨¡å‹ {i+1}/{len(Config.ENSEMBLE_MODELS)}: {model_type}")
            print("-" * 50)

            # åˆ›å»ºæ¨¡å‹
            if args.mode in ['quick', 'fast']:
                model = create_efficient_model(
                    model_type=model_type,
                    num_classes=len(class_names),
                    pretrained=Config.PRETRAINED,
                    dropout_rate=Config.DROPOUT_RATE
                )
            else:
                model = get_model(
                    model_type=model_type,
                    num_classes=len(class_names),
                    pretrained=Config.PRETRAINED,
                    dropout_rate=Config.DROPOUT_RATE
                )

            # åˆ›å»ºè®­ç»ƒå™¨
            trainer = Trainer(
                model=model,
                train_loader=train_loader,
                valid_loader=valid_loader,
                test_loader=test_loader,
                config=Config
            )

            # è®­ç»ƒæ¨¡å‹
            history, test_acc, predictions, targets = trainer.train()

            # ä¿å­˜æ¨¡å‹å’Œç»“æœ
            models[model_type] = model
            val_accuracies.append(max(history['val_acc']))
            trainer.save_model(f'best_{model_type}.pth')

            print(f"{model_type} æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {max(history['val_acc']):.4f}")

        # é›†æˆé¢„æµ‹
        print(f"\nğŸ¯ é›†æˆé¢„æµ‹...")
        ensemble_predictions = []
        all_targets = []

        # è®¾ç½®æ‰€æœ‰æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        for model in models.values():
            model.eval()
            model.to(device)

        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(device), target.to(device)

                # æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹æ¦‚ç‡
                batch_probs = []
                for model in models.values():
                    output = model(data)
                    probs = torch.softmax(output, dim=1)
                    batch_probs.append(probs.cpu().numpy())

                # å¹³å‡æ¦‚ç‡
                avg_probs = np.mean(batch_probs, axis=0)
                predictions = np.argmax(avg_probs, axis=1)

                ensemble_predictions.extend(predictions)
                all_targets.extend(target.cpu().numpy())

        # è®¡ç®—é›†æˆå‡†ç¡®ç‡
        ensemble_acc = sum(p == t for p, t in zip(ensemble_predictions, all_targets)) / len(all_targets)

        # è¯„ä¼°é›†æˆç»“æœ
        print("\nğŸ“ˆ é›†æˆæ¨¡å‹è¯„ä¼°...")
        results = evaluate_model(
            predictions=ensemble_predictions,
            targets=all_targets,
            class_names=class_names,
            save_dir=Config.RESULTS_DIR if Config.SAVE_PLOTS else None
        )

        # æ˜¾ç¤ºç»“æœå¯¹æ¯”
        print("\nğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”:")
        print("-" * 50)
        for model_type, val_acc in zip(Config.ENSEMBLE_MODELS, val_accuracies):
            print(f"{model_type:15s}: {val_acc:.4f}")
        print(f"{'é›†æˆæ¨¡å‹':15s}: {ensemble_acc:.4f}")
        print(f"{'æœ€ä½³å•æ¨¡å‹':15s}: {max(val_accuracies):.4f}")
        print(f"{'é›†æˆæå‡':15s}: {ensemble_acc - max(val_accuracies):+.4f}")

        return ensemble_acc, results, models

    except Exception as e:
        print(f"âŒ é›†æˆè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ å²©çŸ³å›¾åƒåˆ†ç±»ç³»ç»Ÿ v2.0")
    print("=" * 70)

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()

    # æ›´æ–°é…ç½®
    update_config(args)

    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(42)

    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print(f"\nâš™ï¸  é…ç½®ä¿¡æ¯:")
    print(f"   æ¨¡å‹: {Config.MODEL_TYPE}")
    print(f"   è®­ç»ƒè½®æ•°: {Config.EPOCHS}")
    print(f"   æ‰¹æ¬¡å¤§å°: {Config.BATCH_SIZE}")
    print(f"   å­¦ä¹ ç‡: {Config.LEARNING_RATE}")
    print(f"   ä¼˜åŒ–å™¨: {Config.OPTIMIZER}")
    print(f"   è°ƒåº¦å™¨: {Config.LR_SCHEDULER}")
    print(f"   é¢„è®­ç»ƒ: {Config.PRETRAINED}")
    print(f"   æ··åˆç²¾åº¦: {Config.MIXED_PRECISION}")
    print(f"   é›†æˆå­¦ä¹ : {Config.ENSEMBLE}")

    try:
        if Config.ENSEMBLE:
            # é›†æˆå­¦ä¹ è®­ç»ƒ
            result = train_ensemble_models(args)
            if result is not None:
                ensemble_acc, results, models = result

                print("\nğŸ‰ é›†æˆå­¦ä¹ è®­ç»ƒå®Œæˆ!")
                print(f"ğŸ¯ é›†æˆæ¨¡å‹å‡†ç¡®ç‡: {ensemble_acc:.4f}")

                if ensemble_acc >= 0.8:
                    print("ğŸ† æ­å–œï¼è¾¾åˆ°äº†80%ä»¥ä¸Šçš„ç›®æ ‡å‡†ç¡®ç‡ï¼")
                elif ensemble_acc >= 0.75:
                    print("âœ… è¾¾åˆ°äº†75%ä»¥ä¸Šçš„å‡†ç¡®ç‡ï¼Œéå¸¸æ¥è¿‘ç›®æ ‡ï¼")
                else:
                    print("ğŸ“ˆ å‡†ç¡®ç‡æœ‰å¾…æå‡ï¼Œå»ºè®®å°è¯•æ›´å¤šä¼˜åŒ–ç­–ç•¥")
        else:
            # å•æ¨¡å‹è®­ç»ƒ
            result = train_single_model(args)
            if result is not None:
                test_acc, results, trainer = result

                print("\nğŸ‰ å•æ¨¡å‹è®­ç»ƒå®Œæˆ!")
                print(f"ğŸ¯ æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")

                if test_acc >= 0.8:
                    print("ğŸ† æ­å–œï¼è¾¾åˆ°äº†80%ä»¥ä¸Šçš„ç›®æ ‡å‡†ç¡®ç‡ï¼")
                elif test_acc >= 0.7:
                    print("âœ… è¾¾åˆ°äº†70%ä»¥ä¸Šçš„å‡†ç¡®ç‡ï¼Œè¡¨ç°è‰¯å¥½ï¼")
                    print("ğŸ’¡ å»ºè®®å°è¯•é›†æˆå­¦ä¹ ä»¥è¿›ä¸€æ­¥æå‡: --ensemble")
                else:
                    print("ğŸ“ˆ å‡†ç¡®ç‡æœ‰å¾…æå‡ï¼Œå»ºè®®:")
                    print("   - å°è¯•é›†æˆå­¦ä¹ : --ensemble")
                    print("   - å¢åŠ è®­ç»ƒè½®æ•°: --epochs 50")
                    print("   - ä½¿ç”¨æ›´å¤§æ¨¡å‹: --model resnet50")

        # GPUå»ºè®®
        if not torch.cuda.is_available():
            print("\nğŸ’¡ æ€§èƒ½æå‡å»ºè®®:")
            print("   å½“å‰ä½¿ç”¨CPUè®­ç»ƒã€‚å¦‚æœæœ‰NVIDIA GPUï¼Œå¯ä»¥å®‰è£…CUDAç‰ˆæœ¬:")
            print("   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118")
            print("   è¿™å°†å¤§å¤§æå‡è®­ç»ƒé€Ÿåº¦å’Œæ¨¡å‹æ€§èƒ½ï¼")

        # ä½¿ç”¨å»ºè®®
        print("\nğŸ“š æ›´å¤šä½¿ç”¨æ–¹å¼:")
        print("   å¿«é€Ÿæµ‹è¯•: python main.py --mode quick")
        print("   å¿«é€Ÿè®­ç»ƒ: python main.py --mode fast")
        print("   å®Œæ•´è®­ç»ƒ: python main.py --model resnet50 --epochs 50")
        print("   é›†æˆå­¦ä¹ : python main.py --ensemble --epochs 30")

    except KeyboardInterrupt:
        print("\nâ¹ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()